{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hmmohamed/anaconda3/envs/infs890/bin/python\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import random\n",
    "\n",
    "print(sys.executable)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULTS = [[0.0] for x in range(0, SEQ_LEN)]\n",
    "BATCH_SIZE = 20\n",
    "TIMESERIES_COL = 'rawdata'\n",
    "N_OUTPUTS = 2  # in each sequence, 1-8 are features, and 9-10 is label\n",
    "N_INPUTS = SEQ_LEN - N_OUTPUTS\n",
    "\n",
    "SAMPLE_SIZE = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[random.random() for x in range(SEQ_LEN)] for y in range(SAMPLE_SIZE)]\n",
    "np.savetxt('tf_rnn_tutorial.txt', data, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data and convert to needed format\n",
    "def read_dataset(filename, mode=tf.contrib.learn.ModeKeys.TRAIN):\n",
    "    def _input_fn():\n",
    "        num_epochs = 100 if mode == tf.contrib.learn.ModeKeys.TRAIN else 1\n",
    "        # could be a path to one file or a file pattern.\n",
    "        input_file_names = tf.train.match_filenames_once(filename)\n",
    "        filename_queue = tf.train.string_input_producer(\n",
    "        input_file_names, num_epochs=num_epochs, shuffle=True)\n",
    "        reader = tf.TextLineReader()\n",
    "        _, value = reader.read_up_to(filename_queue, num_records=BATCH_SIZE)\n",
    "        value_column = tf.expand_dims(value, -1)\n",
    "        # all_data is a list of tensors\n",
    "        all_data = tf.decode_csv(value_column, record_defaults=DEFAULTS)\n",
    "        inputs = all_data[:len(all_data)-N_OUTPUTS]  # first few values\n",
    "        label = all_data[len(all_data)-N_OUTPUTS : ] # last few values\n",
    "\n",
    "        # from list of tensors to tensor with one more dimension\n",
    "        inputs = tf.concat(inputs, axis=1)\n",
    "        label = tf.concat(label, axis=1)\n",
    "        print ('inputs={}'.format(inputs))\n",
    "\n",
    "        return {TIMESERIES_COL: inputs}, label   # dict of features, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
