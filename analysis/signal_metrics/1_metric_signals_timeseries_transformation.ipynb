{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Raw Signal Metrics Data Transformation\n",
    "\n",
    "This file to be executed first\n",
    "\n",
    "This notebook transforms raw metrics signals into adequate values and saves them as time series data to different output files. The outputfiles will be having data in columns named as 'date', 'metric', 'value'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1- read processed file\n",
    "\n",
    "home_dir = '/Users/hmohamed/github/data-research-spring2020'\n",
    "\n",
    "file_dir = home_dir + '/raw-data-linode-run3/'\n",
    "merged_dir = file_dir + 'merged/' \n",
    "\n",
    "# containers / istio input files\n",
    "service_cpu_usage_file = '1_service_cpu_use.csv'\n",
    "service_memory_usage_file = '2_service_memory_use.csv'\n",
    "service_cpu_sat_file = '3_service_cpu_sat.csv'\n",
    "service_net_usage_file = '4_service_net_usage.csv'\n",
    "service_disk_usage_file = '5_service_disk_usage.csv'\n",
    "service_req_total_file = '6_service_req_total.csv'\n",
    "#service_ltcy_file = '7_service_ltcy_200.csv'\n",
    "service_errors_file = '8_service_errors.csv'\n",
    "service_request_size_file = '9_service_request_size.csv'\n",
    "service_response_size_file = '10_service_response_size.csv'\n",
    "containers_count_file = '11_containers_count.csv'\n",
    "system_network_receive = '15_system_network_receive.csv'\n",
    "system_network_transmit = '16_system_network_transmit.csv'\n",
    "service_ltcy_sum = '17_service_ltcy_sum.csv'\n",
    "service_ltcy_count = '18_service_ltcy_count.csv'\n",
    "\n",
    "node_load1_file = '13_node_load1.csv'\n",
    "node_cpu_seconds_total_file = '14_node_cpu_seconds_total.csv'\n",
    "\n",
    "# system input files\n",
    "system_cpu_usage_file = '12_system_cpu_usage.csv'\n",
    "\n",
    "\n",
    "service_input_files = [service_cpu_usage_file\n",
    "                      , service_memory_usage_file\n",
    "                      , service_cpu_sat_file\n",
    "                      , service_net_usage_file\n",
    "                      , service_disk_usage_file\n",
    "                      , service_req_total_file\n",
    "                      #, service_ltcy_file\n",
    "                      , service_ltcy_sum\n",
    "                      , service_ltcy_count\n",
    "                      , service_errors_file\n",
    "                      , service_request_size_file\n",
    "                      , service_response_size_file                       \n",
    "                      , containers_count_file\n",
    "                     ]\n",
    "\n",
    "system_input_files = [\n",
    "    system_cpu_usage_file\n",
    "#    ,system_network_receive\n",
    "#    ,system_network_transmit\n",
    "    \n",
    "]\n",
    "\n",
    "concated_data_file = 'all_data.csv'\n",
    "\n",
    "services = ['checkoutservice'\n",
    ",'cartservice'\n",
    ",'emailservice'\n",
    ",'currencyservice'\n",
    ",'paymentservice'\n",
    ",'productcatalogservice'\n",
    ",'shippingservice'\n",
    "] \n",
    "\n",
    "\n",
    "save=True\n",
    "frequency = '1S'  # S for second , T for minute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function merges and alines the metrics timeseries data into a data frame, a column for every feature\n",
    "def expand(df, by_col, by_col_values, dup='sum'):\n",
    "    # first convert to time series\n",
    "    df = toTimeSeries(df, 'date')\n",
    "    metrics_df = pd.DataFrame()\n",
    "    i = 0\n",
    "    for col_value in by_col_values:\n",
    "        print(\"Processing metric for column: %\", col_value)\n",
    "        series = extractMetricSeries(df, by_col, col_value)\n",
    "        series = resample(series, value_column_name=col_value, dup=dup)  \n",
    "        if i == 0:\n",
    "            metrics_df = series\n",
    "        else:\n",
    "            metrics_df = merge(metrics_df, series)\n",
    "        i = i + 1\n",
    "    return metrics_df \n",
    "\n",
    "# T for minutes, S for seconds\n",
    "# remedy duplicates by either taking the maximum (=max) or average  (=mean) them\n",
    "def resample(df, value_column_name, index_col_name='date', frequency = frequency, interpolate = True\n",
    "             , interpolate_method = 'linear', base=6, dup = 'sum'):\n",
    "    # eliminate dups in timestamp\n",
    "    if dup == 'max':\n",
    "        df = df.groupby([index_col_name])[value_column_name].max()   # taking max\n",
    "        df = pd.DataFrame(df)\n",
    "    elif dup == 'sum':\n",
    "        df = df.groupby([index_col_name])[value_column_name].sum()\n",
    "    else:\n",
    "        df = df.groupby([index_col_name]).mean()   # taking mean\n",
    "        \n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df.sort_index(inplace=True)  # order the timeseries\n",
    "    \n",
    "    # fill in missing interval (upsample)\n",
    "    shape_before = df.shape\n",
    "    resampled = df.resample(frequency, kind='timestamp', base=base)  #.bfill()\n",
    "    \n",
    "    if interpolate:\n",
    "        resampled = resampled.interpolate(method=interpolate_method)    \n",
    "        \n",
    "    print(\"dimention before resampling is: {}\".format(shape_before))\n",
    "    return resampled\n",
    "\n",
    "def toTimeSeries(df, index_col_name='date', value_col_name='value'):\n",
    "    df[index_col_name] = pd.to_datetime(df[index_col_name])\n",
    "    df[value_col_name] = pd.to_numeric(df[value_col_name])\n",
    "    df.set_index(index_col_name, inplace=True)\n",
    "    df.sort_index(inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# This function extracts timeseries of one named service from the whole raw timeseries data\n",
    "def extractMetricSeries(df, col_name, col_value):\n",
    "    metric = df.loc[df[col_name] == col_value].drop([col_name], axis=1).rename(index=str, columns={\"value\": col_value})\n",
    "    metric.sort_index(inplace=True)\n",
    "    return metric  \n",
    "\n",
    "# sum df rows, remove expanded columns and set a new column with a metric name\n",
    "def sumTimeseries(df, columns_to_delete, metric_name, metric_col_name='metric'):\n",
    "    df['value'] = df.sum(axis=1)\n",
    "    df[metric_col_name] = metric_name\n",
    "    for col in columns_to_delete:\n",
    "        df = df.drop([col], axis=1)\n",
    "    return df \n",
    "\n",
    "# max df rows, remove expanded columns and set a new column with a metric name\n",
    "def maxTimeseries(df, columns_to_delete, metric_name, metric_col_name='metric'):\n",
    "    df['value'] = df.max(axis=1)\n",
    "    df[metric_col_name] = metric_name\n",
    "    for col in columns_to_delete:\n",
    "        df = df.drop([col], axis=1)\n",
    "    return df\n",
    "\n",
    "# average df rows, remove expanded columns and set a new column with a metric name\n",
    "def avgTimeseries(df, columns_to_delete, metric_name, metric_col_name='metric'):\n",
    "    df['value'] = df.mean(axis=1)\n",
    "    df[metric_col_name] = metric_name\n",
    "    for col in columns_to_delete:\n",
    "        df = df.drop([col], axis=1)\n",
    "    return df\n",
    "\n",
    "# average df rows, remove expanded columns and set a new column with a metric name\n",
    "def countTimeseries(df, columns_to_delete, metric_name, metric_col_name='metric'):\n",
    "    df['value'] = df.count(axis=1)\n",
    "    df[metric_col_name] = metric_name\n",
    "    for col in columns_to_delete:\n",
    "        df = df.drop([col], axis=1)\n",
    "    return df\n",
    "\n",
    "def merge(df, series):\n",
    "    return pd.merge_asof(df, series, left_index=True, right_index=True, tolerance=pd.Timedelta('1 second')).bfill()    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing input file 1_service_cpu_use.csv\n",
      "processing metric service_cpu_use\n",
      "Processing metric for column: % checkoutservice\n",
      "dimention before resampling is: (31755,)\n",
      "Processing metric for column: % cartservice\n",
      "dimention before resampling is: (33399,)\n",
      "Processing metric for column: % emailservice\n",
      "dimention before resampling is: (32712,)\n",
      "Processing metric for column: % currencyservice\n",
      "dimention before resampling is: (33053,)\n",
      "Processing metric for column: % paymentservice\n",
      "dimention before resampling is: (32376,)\n",
      "Processing metric for column: % productcatalogservice\n",
      "dimention before resampling is: (33172,)\n",
      "Processing metric for column: % shippingservice\n",
      "dimention before resampling is: (32077,)\n",
      "saving 1_service_cpu_use.csv data with shape (78845, 2)\n",
      "----------------\n",
      "processing input file 2_service_memory_use.csv\n",
      "processing metric service_memory_use\n",
      "Processing metric for column: % checkoutservice\n",
      "dimention before resampling is: (31682,)\n",
      "Processing metric for column: % cartservice\n",
      "dimention before resampling is: (33436,)\n",
      "Processing metric for column: % emailservice\n",
      "dimention before resampling is: (32834,)\n",
      "Processing metric for column: % currencyservice\n",
      "dimention before resampling is: (33078,)\n",
      "Processing metric for column: % paymentservice\n",
      "dimention before resampling is: (32493,)\n",
      "Processing metric for column: % productcatalogservice\n",
      "dimention before resampling is: (33131,)\n",
      "Processing metric for column: % shippingservice\n",
      "dimention before resampling is: (32063,)\n",
      "saving 2_service_memory_use.csv data with shape (78844, 2)\n",
      "----------------\n",
      "processing input file 3_service_cpu_sat.csv\n",
      "processing metric service_cpu_sat\n",
      "Processing metric for column: % checkoutservice\n",
      "dimention before resampling is: (24570,)\n",
      "Processing metric for column: % cartservice\n",
      "dimention before resampling is: (26197,)\n",
      "Processing metric for column: % emailservice\n",
      "dimention before resampling is: (26203,)\n",
      "Processing metric for column: % currencyservice\n",
      "dimention before resampling is: (26123,)\n",
      "Processing metric for column: % paymentservice\n",
      "dimention before resampling is: (25762,)\n",
      "Processing metric for column: % productcatalogservice\n",
      "dimention before resampling is: (25937,)\n",
      "Processing metric for column: % shippingservice\n",
      "dimention before resampling is: (26098,)\n",
      "saving 3_service_cpu_sat.csv data with shape (78850, 2)\n",
      "----------------\n",
      "processing input file 4_service_net_usage.csv\n",
      "processing metric service_net_usage\n",
      "Processing metric for column: % checkoutservice\n",
      "dimention before resampling is: (11626,)\n",
      "Processing metric for column: % cartservice\n",
      "dimention before resampling is: (11643,)\n",
      "Processing metric for column: % emailservice\n",
      "dimention before resampling is: (11637,)\n",
      "Processing metric for column: % currencyservice\n",
      "dimention before resampling is: (11567,)\n",
      "Processing metric for column: % paymentservice\n",
      "dimention before resampling is: (11386,)\n",
      "Processing metric for column: % productcatalogservice\n",
      "dimention before resampling is: (11572,)\n",
      "Processing metric for column: % shippingservice\n",
      "dimention before resampling is: (11574,)\n",
      "saving 4_service_net_usage.csv data with shape (78847, 2)\n",
      "----------------\n",
      "processing input file 5_service_disk_usage.csv\n",
      "processing metric service_disk_usage\n",
      "Processing metric for column: % checkoutservice\n",
      "dimention before resampling is: (24505,)\n",
      "Processing metric for column: % cartservice\n",
      "dimention before resampling is: (26286,)\n",
      "Processing metric for column: % emailservice\n",
      "dimention before resampling is: (26409,)\n",
      "Processing metric for column: % currencyservice\n",
      "dimention before resampling is: (26092,)\n",
      "Processing metric for column: % paymentservice\n",
      "dimention before resampling is: (25841,)\n",
      "Processing metric for column: % productcatalogservice\n",
      "dimention before resampling is: (26068,)\n",
      "Processing metric for column: % shippingservice\n",
      "dimention before resampling is: (26219,)\n",
      "saving 5_service_disk_usage.csv data with shape (78849, 2)\n",
      "----------------\n",
      "processing input file 6_service_req_total.csv\n",
      "processing metric service_req_total\n",
      "Processing metric for column: % checkoutservice\n",
      "dimention before resampling is: (4989,)\n",
      "Processing metric for column: % cartservice\n",
      "dimention before resampling is: (0,)\n",
      "Processing metric for column: % emailservice\n",
      "dimention before resampling is: (0,)\n",
      "Processing metric for column: % currencyservice\n",
      "dimention before resampling is: (0,)\n",
      "Processing metric for column: % paymentservice\n",
      "dimention before resampling is: (0,)\n",
      "Processing metric for column: % productcatalogservice\n",
      "dimention before resampling is: (0,)\n",
      "Processing metric for column: % shippingservice\n",
      "dimention before resampling is: (0,)\n",
      "saving 6_service_req_total.csv data with shape (78841, 2)\n",
      "----------------\n",
      "processing input file 17_service_ltcy_sum.csv\n",
      "processing metric service_ltcy_sum\n",
      "Processing metric for column: % checkoutservice\n",
      "dimention before resampling is: (4979,)\n",
      "Processing metric for column: % cartservice\n",
      "dimention before resampling is: (0,)\n",
      "Processing metric for column: % emailservice\n",
      "dimention before resampling is: (0,)\n",
      "Processing metric for column: % currencyservice\n",
      "dimention before resampling is: (0,)\n",
      "Processing metric for column: % paymentservice\n",
      "dimention before resampling is: (0,)\n",
      "Processing metric for column: % productcatalogservice\n",
      "dimention before resampling is: (0,)\n",
      "Processing metric for column: % shippingservice\n",
      "dimention before resampling is: (0,)\n",
      "saving 17_service_ltcy_sum.csv data with shape (78841, 2)\n",
      "----------------\n",
      "processing input file 18_service_ltcy_count.csv\n",
      "processing metric service_ltcy_count\n",
      "Processing metric for column: % checkoutservice\n",
      "dimention before resampling is: (4976,)\n",
      "Processing metric for column: % cartservice\n",
      "dimention before resampling is: (0,)\n",
      "Processing metric for column: % emailservice\n",
      "dimention before resampling is: (0,)\n",
      "Processing metric for column: % currencyservice\n",
      "dimention before resampling is: (0,)\n",
      "Processing metric for column: % paymentservice\n",
      "dimention before resampling is: (0,)\n",
      "Processing metric for column: % productcatalogservice\n",
      "dimention before resampling is: (0,)\n",
      "Processing metric for column: % shippingservice\n",
      "dimention before resampling is: (0,)\n",
      "saving 18_service_ltcy_count.csv data with shape (78841, 2)\n",
      "----------------\n",
      "processing input file 8_service_errors.csv\n",
      "processing metric service_errors\n",
      "Processing metric for column: % checkoutservice\n",
      "dimention before resampling is: (552,)\n",
      "Processing metric for column: % cartservice\n",
      "dimention before resampling is: (899,)\n",
      "Processing metric for column: % emailservice\n",
      "dimention before resampling is: (461,)\n",
      "Processing metric for column: % currencyservice\n",
      "dimention before resampling is: (1017,)\n",
      "Processing metric for column: % paymentservice\n",
      "dimention before resampling is: (486,)\n",
      "Processing metric for column: % productcatalogservice\n",
      "dimention before resampling is: (2205,)\n",
      "Processing metric for column: % shippingservice\n",
      "dimention before resampling is: (497,)\n",
      "saving 8_service_errors.csv data with shape (78841, 2)\n",
      "----------------\n",
      "processing input file 9_service_request_size.csv\n",
      "processing metric service_request_size\n",
      "Processing metric for column: % checkoutservice\n",
      "dimention before resampling is: (4985,)\n",
      "Processing metric for column: % cartservice\n",
      "dimention before resampling is: (5063,)\n",
      "Processing metric for column: % emailservice\n",
      "dimention before resampling is: (4895,)\n",
      "Processing metric for column: % currencyservice\n",
      "dimention before resampling is: (5064,)\n",
      "Processing metric for column: % paymentservice\n",
      "dimention before resampling is: (4910,)\n",
      "Processing metric for column: % productcatalogservice\n",
      "dimention before resampling is: (5069,)\n",
      "Processing metric for column: % shippingservice\n",
      "dimention before resampling is: (5039,)\n",
      "saving 9_service_request_size.csv data with shape (78841, 2)\n",
      "----------------\n",
      "processing input file 10_service_response_size.csv\n",
      "processing metric service_response_size\n",
      "Processing metric for column: % checkoutservice\n",
      "dimention before resampling is: (4965,)\n",
      "Processing metric for column: % cartservice\n",
      "dimention before resampling is: (5057,)\n",
      "Processing metric for column: % emailservice\n",
      "dimention before resampling is: (4905,)\n",
      "Processing metric for column: % currencyservice\n",
      "dimention before resampling is: (5055,)\n",
      "Processing metric for column: % paymentservice\n",
      "dimention before resampling is: (4928,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing metric for column: % productcatalogservice\n",
      "dimention before resampling is: (5065,)\n",
      "Processing metric for column: % shippingservice\n",
      "dimention before resampling is: (5036,)\n",
      "saving 10_service_response_size.csv data with shape (78841, 2)\n",
      "----------------\n",
      "processing input file 11_containers_count.csv\n",
      "processing metric containers_count\n",
      "Processing metric for column: % checkoutservice\n",
      "dimention before resampling is: (5204,)\n",
      "Processing metric for column: % cartservice\n",
      "dimention before resampling is: (5208,)\n",
      "Processing metric for column: % emailservice\n",
      "dimention before resampling is: (5208,)\n",
      "Processing metric for column: % currencyservice\n",
      "dimention before resampling is: (5211,)\n",
      "Processing metric for column: % paymentservice\n",
      "dimention before resampling is: (5207,)\n",
      "Processing metric for column: % productcatalogservice\n",
      "dimention before resampling is: (5203,)\n",
      "Processing metric for column: % shippingservice\n",
      "dimention before resampling is: (5214,)\n",
      "saving 11_containers_count.csv data with shape (78826, 2)\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "# process istio and container metrics data signals\n",
    "for file in service_input_files:\n",
    "    orig_file = file\n",
    "    print('processing input file {}'.format(file))\n",
    "    pos = file.find('_')\n",
    "    metric_name = file[pos+1:]\n",
    "    pos = metric_name.find('.')\n",
    "    metric_name = metric_name[:pos]\n",
    "    print('processing metric {}'.format(metric_name))\n",
    "    \n",
    "    data_df = pd.read_csv(file_dir + file)\n",
    "    data_df.rename(columns={'ztime': 'date', 'name':'metric'}, inplace=True)\n",
    "        \n",
    "    # expand and either average or max any duplicates in timestamps series\n",
    "    expanded_df = expand(data_df, by_col='service', by_col_values=services)\n",
    "    \n",
    "    # sum timeseries rows (accumulate the services)\n",
    "    sum_df = sumTimeseries(expanded_df, columns_to_delete=services, metric_name=metric_name)\n",
    "\n",
    "    if save:\n",
    "        print('saving {} data with shape {}'.format(orig_file, sum_df.shape))\n",
    "        save_to_file = merged_dir + orig_file\n",
    "        sum_df.to_csv(path_or_buf=save_to_file, index=True) \n",
    "        print(\"----------------\")\n",
    "    else:\n",
    "        print(\"Metric data is not saved. Savig flag is turned off!\")        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# system_cpu_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing metric for column: % 192.168.181.164\n",
      "dimention before resampling is: (5257, 1)\n",
      "Processing metric for column: % 192.168.228.12\n",
      "dimention before resampling is: (5257, 1)\n",
      "Processing metric for column: % 192.168.227.189\n",
      "dimention before resampling is: (4676, 1)\n",
      "Processing metric for column: % 192.168.189.71\n",
      "dimention before resampling is: (5257, 1)\n",
      "Processing metric for column: % 192.168.227.202\n",
      "dimention before resampling is: (5256, 1)\n",
      "saving system_cpu_usage to file /Users/hmohamed/github/data-research-spring2020/raw-data-linode-run3/merged/12_system_cpu_usage.csv with dimension (78841, 2)\n"
     ]
    }
   ],
   "source": [
    "# system_cpu_usage\n",
    "system_cpu_usage_df = pd.read_csv(file_dir + system_cpu_usage_file)\n",
    "system_cpu_usage_df.rename(columns={'ztime': 'date', 'name':'metric'}, inplace=True)\n",
    "\n",
    "# find nodes in the system\n",
    "nodes = system_cpu_usage_df.dropna(subset=['node']).node.unique()\n",
    "\n",
    "system_cpu_usage_expanded = expand(system_cpu_usage_df, by_col='node'\n",
    "                                   , by_col_values=nodes, dup='mean')\n",
    "\n",
    "system_cpu_usage_sum = sumTimeseries(system_cpu_usage_expanded, columns_to_delete=nodes\n",
    "                                          , metric_name='system_cpu_usage')\n",
    "\n",
    "if save:\n",
    "    print('saving system_cpu_usage to file {} with dimension {}'.format(merged_dir + system_cpu_usage_file, system_cpu_usage_sum.shape))       \n",
    "    system_cpu_usage_sum.to_csv(path_or_buf=merged_dir + system_cpu_usage_file, index=True) \n",
    "else:\n",
    "    print(\"system_cpu_usage data is not saved. Savig flag is turned off!\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# system_cpu_sat\n",
    "\n",
    "--- skip ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing metric for column: % 192.168.181.164\n",
      "dimention before resampling is: (7485,)\n",
      "Processing metric for column: % 192.168.228.12\n",
      "dimention before resampling is: (7580,)\n",
      "Processing metric for column: % 192.168.227.189\n",
      "dimention before resampling is: (6922,)\n",
      "Processing metric for column: % 192.168.189.71\n",
      "dimention before resampling is: (7703,)\n",
      "Processing metric for column: % 192.168.227.202\n",
      "dimention before resampling is: (7130,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>192.168.181.164</th>\n",
       "      <th>192.168.228.12</th>\n",
       "      <th>192.168.227.189</th>\n",
       "      <th>192.168.189.71</th>\n",
       "      <th>192.168.227.202</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-27 16:36:28</th>\n",
       "      <td>1.210</td>\n",
       "      <td>0.866</td>\n",
       "      <td>10.176</td>\n",
       "      <td>0.478000</td>\n",
       "      <td>0.996667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-27 16:36:29</th>\n",
       "      <td>1.192</td>\n",
       "      <td>0.872</td>\n",
       "      <td>10.108</td>\n",
       "      <td>0.470667</td>\n",
       "      <td>1.013333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-27 16:36:30</th>\n",
       "      <td>1.174</td>\n",
       "      <td>0.878</td>\n",
       "      <td>10.040</td>\n",
       "      <td>0.463333</td>\n",
       "      <td>1.030000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     192.168.181.164  192.168.228.12  192.168.227.189  \\\n",
       "date                                                                    \n",
       "2020-02-27 16:36:28            1.210           0.866           10.176   \n",
       "2020-02-27 16:36:29            1.192           0.872           10.108   \n",
       "2020-02-27 16:36:30            1.174           0.878           10.040   \n",
       "\n",
       "                     192.168.189.71  192.168.227.202  \n",
       "date                                                  \n",
       "2020-02-27 16:36:28        0.478000         0.996667  \n",
       "2020-02-27 16:36:29        0.470667         1.013333  \n",
       "2020-02-27 16:36:30        0.463333         1.030000  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# skip system_cpu_sat\n",
    "# system_cpu_sat\n",
    "node_load_df = pd.read_csv(file_dir + node_load1_file)\n",
    "node_load_df.rename(columns={'ztime': 'date', 'name':'metric'}, inplace=True)\n",
    "node_load_expanded = expand(node_load_df, by_col='node'\n",
    "                                   , by_col_values=nodes, dup='sum')\n",
    "nodes = node_load_expanded.columns\n",
    "\n",
    "node_load_expanded.head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing metric for column: % 192.168.181.164\n",
      "dimention before resampling is: (8404, 1)\n",
      "Processing metric for column: % 192.168.228.12\n",
      "dimention before resampling is: (8422, 1)\n",
      "Processing metric for column: % 192.168.227.189\n",
      "dimention before resampling is: (7632, 1)\n",
      "Processing metric for column: % 192.168.189.71\n",
      "dimention before resampling is: (8419, 1)\n",
      "Processing metric for column: % 192.168.227.202\n",
      "dimention before resampling is: (8413, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>192.168.181.164</th>\n",
       "      <th>192.168.228.12</th>\n",
       "      <th>192.168.227.189</th>\n",
       "      <th>192.168.189.71</th>\n",
       "      <th>192.168.227.202</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-27 16:36:28</th>\n",
       "      <td>847.720</td>\n",
       "      <td>104.499667</td>\n",
       "      <td>468.161000</td>\n",
       "      <td>241.6715</td>\n",
       "      <td>241.963333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-27 16:36:29</th>\n",
       "      <td>847.805</td>\n",
       "      <td>104.514333</td>\n",
       "      <td>468.212167</td>\n",
       "      <td>241.6920</td>\n",
       "      <td>241.985167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-27 16:36:30</th>\n",
       "      <td>847.890</td>\n",
       "      <td>104.529000</td>\n",
       "      <td>468.263333</td>\n",
       "      <td>241.7125</td>\n",
       "      <td>242.007000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     192.168.181.164  192.168.228.12  192.168.227.189  \\\n",
       "date                                                                    \n",
       "2020-02-27 16:36:28          847.720      104.499667       468.161000   \n",
       "2020-02-27 16:36:29          847.805      104.514333       468.212167   \n",
       "2020-02-27 16:36:30          847.890      104.529000       468.263333   \n",
       "\n",
       "                     192.168.189.71  192.168.227.202  \n",
       "date                                                  \n",
       "2020-02-27 16:36:28        241.6715       241.963333  \n",
       "2020-02-27 16:36:29        241.6920       241.985167  \n",
       "2020-02-27 16:36:30        241.7125       242.007000  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# skip system_cpu_sat\n",
    "# system_cpu_sat\n",
    "node_cpu_total_df = pd.read_csv(file_dir + node_cpu_seconds_total_file)\n",
    "node_cpu_total_df.rename(columns={'ztime': 'date', 'name':'metric'}, inplace=True)\n",
    "node_cpu_total_expanded = expand(node_cpu_total_df, by_col='node'\n",
    "                                   , by_col_values=nodes, dup='count')\n",
    "node_cpu_total_expanded.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# system_network_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing metric for column: % 192.168.228.12\n",
      "dimention before resampling is: (8464, 1)\n",
      "Processing metric for column: % 192.168.189.71\n",
      "dimention before resampling is: (8470, 1)\n",
      "Processing metric for column: % 192.168.227.189\n",
      "dimention before resampling is: (7692, 1)\n",
      "Processing metric for column: % 192.168.227.202\n",
      "dimention before resampling is: (8467, 1)\n",
      "Processing metric for column: % 192.168.181.164\n",
      "dimention before resampling is: (8468, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-27 16:36:27</th>\n",
       "      <td>8.686654e+08</td>\n",
       "      <td>system_network_receive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-27 16:36:28</th>\n",
       "      <td>8.687398e+08</td>\n",
       "      <td>system_network_receive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-27 16:36:29</th>\n",
       "      <td>8.688182e+08</td>\n",
       "      <td>system_network_receive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            value                  metric\n",
       "date                                                     \n",
       "2020-02-27 16:36:27  8.686654e+08  system_network_receive\n",
       "2020-02-27 16:36:28  8.687398e+08  system_network_receive\n",
       "2020-02-27 16:36:29  8.688182e+08  system_network_receive"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# System network recieve\n",
    "system_net_receive_df = pd.read_csv(file_dir + system_network_receive)\n",
    "system_net_receive_df.rename(columns={'ztime': 'date', 'name':'metric'}, inplace=True)\n",
    "\n",
    "# find nodes in the system\n",
    "nodes = system_net_receive_df.dropna(subset=['node']).node.unique()\n",
    "\n",
    "system_net_receive_expanded = expand(system_net_receive_df, by_col='node'\n",
    "                                   , by_col_values=nodes, dup='mean')\n",
    "\n",
    "system_net_receive_sum = sumTimeseries(system_net_receive_expanded, columns_to_delete=nodes\n",
    "                                          , metric_name='system_network_receive')\n",
    "\n",
    "system_net_receive_sum.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127614, 2)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_net_receive_sum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing metric for column: % 192.168.228.12\n",
      "dimention before resampling is: (8462, 1)\n",
      "Processing metric for column: % 192.168.189.71\n",
      "dimention before resampling is: (8469, 1)\n",
      "Processing metric for column: % 192.168.227.202\n",
      "dimention before resampling is: (8470, 1)\n",
      "Processing metric for column: % 192.168.227.189\n",
      "dimention before resampling is: (7692, 1)\n",
      "Processing metric for column: % 192.168.181.164\n",
      "dimention before resampling is: (8465, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-27 16:36:27</th>\n",
       "      <td>4.219483e+08</td>\n",
       "      <td>system_network_receive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-27 16:36:28</th>\n",
       "      <td>4.220086e+08</td>\n",
       "      <td>system_network_receive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-27 16:36:29</th>\n",
       "      <td>4.220747e+08</td>\n",
       "      <td>system_network_receive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            value                  metric\n",
       "date                                                     \n",
       "2020-02-27 16:36:27  4.219483e+08  system_network_receive\n",
       "2020-02-27 16:36:28  4.220086e+08  system_network_receive\n",
       "2020-02-27 16:36:29  4.220747e+08  system_network_receive"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# System network recieve\n",
    "system_net_transmit_df = pd.read_csv(file_dir + system_network_transmit)\n",
    "system_net_transmit_df.rename(columns={'ztime': 'date', 'name':'metric'}, inplace=True)\n",
    "\n",
    "# find nodes in the system\n",
    "nodes = system_net_transmit_df.dropna(subset=['node']).node.unique()\n",
    "\n",
    "system_net_transmit_expanded = expand(system_net_transmit_df, by_col='node'\n",
    "                                   , by_col_values=nodes, dup='mean')\n",
    "\n",
    "system_net_transmit_sum = sumTimeseries(system_net_transmit_expanded, columns_to_delete=nodes\n",
    "                                          , metric_name='system_network_receive')\n",
    "\n",
    "system_net_transmit_sum.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127614, 2)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_net_transmit_sum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-27 16:36:27</th>\n",
       "      <td>1.290614e+09</td>\n",
       "      <td>system_network_usage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-27 16:36:28</th>\n",
       "      <td>1.290748e+09</td>\n",
       "      <td>system_network_usage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-27 16:36:29</th>\n",
       "      <td>1.290893e+09</td>\n",
       "      <td>system_network_usage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-27 16:36:30</th>\n",
       "      <td>1.291037e+09</td>\n",
       "      <td>system_network_usage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-27 16:36:31</th>\n",
       "      <td>1.291182e+09</td>\n",
       "      <td>system_network_usage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            value                metric\n",
       "date                                                   \n",
       "2020-02-27 16:36:27  1.290614e+09  system_network_usage\n",
       "2020-02-27 16:36:28  1.290748e+09  system_network_usage\n",
       "2020-02-27 16:36:29  1.290893e+09  system_network_usage\n",
       "2020-02-27 16:36:30  1.291037e+09  system_network_usage\n",
       "2020-02-27 16:36:31  1.291182e+09  system_network_usage"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum network recieved and transmit\n",
    "system_network_usage_df =  system_net_receive_sum['value'] + system_net_transmit_sum['value']\n",
    "\n",
    "system_network_usage_df = pd.DataFrame(system_network_usage_df, columns=['value'])\n",
    "system_network_usage_df['metric'] = 'system_network_usage'\n",
    "system_network_usage_df.sort_index()\n",
    "\n",
    "# check number of nulls\n",
    "nulls = system_network_usage_df.isnull().sum()\n",
    "if nulls['value'] > 0:\n",
    "    ltcy_df = system_network_usage_df.fillna(ltcy_df.mean())\n",
    "        \n",
    "system_network_usage_df.head(5) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate all data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data from /Users/hmohamed/github/data-research-spring2020/raw-data-linode-run3/merged/1_service_cpu_use.csv\n",
      "reading data from /Users/hmohamed/github/data-research-spring2020/raw-data-linode-run3/merged/2_service_memory_use.csv\n",
      "reading data from /Users/hmohamed/github/data-research-spring2020/raw-data-linode-run3/merged/3_service_cpu_sat.csv\n",
      "reading data from /Users/hmohamed/github/data-research-spring2020/raw-data-linode-run3/merged/4_service_net_usage.csv\n",
      "reading data from /Users/hmohamed/github/data-research-spring2020/raw-data-linode-run3/merged/5_service_disk_usage.csv\n",
      "reading data from /Users/hmohamed/github/data-research-spring2020/raw-data-linode-run3/merged/6_service_req_total.csv\n",
      "reading data from /Users/hmohamed/github/data-research-spring2020/raw-data-linode-run3/merged/17_service_ltcy_sum.csv\n",
      "reading data from /Users/hmohamed/github/data-research-spring2020/raw-data-linode-run3/merged/18_service_ltcy_count.csv\n",
      "reading data from /Users/hmohamed/github/data-research-spring2020/raw-data-linode-run3/merged/8_service_errors.csv\n",
      "reading data from /Users/hmohamed/github/data-research-spring2020/raw-data-linode-run3/merged/9_service_request_size.csv\n",
      "reading data from /Users/hmohamed/github/data-research-spring2020/raw-data-linode-run3/merged/10_service_response_size.csv\n",
      "reading data from /Users/hmohamed/github/data-research-spring2020/raw-data-linode-run3/merged/11_containers_count.csv\n",
      "reading data from /Users/hmohamed/github/data-research-spring2020/raw-data-linode-run3/merged/12_system_cpu_usage.csv\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "all_files = service_input_files + system_input_files\n",
    "for file in all_files:\n",
    "    input_file = merged_dir + file\n",
    "    print('reading data from {}'.format(input_file))\n",
    "    input_df = pd.read_csv(input_file)\n",
    "    #input_df = toTimeSeries(input_df)\n",
    "    if i == 1:\n",
    "        timeseries_df = input_df\n",
    "    else:\n",
    "        timeseries_df = pd.concat([timeseries_df, input_df], ignore_index=True)\n",
    "    i = i +1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Latency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>value</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-27 22:49:53</td>\n",
       "      <td>3504.829879</td>\n",
       "      <td>service_cpu_use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-27 22:49:54</td>\n",
       "      <td>5742.951598</td>\n",
       "      <td>service_cpu_use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-27 22:49:55</td>\n",
       "      <td>7981.073317</td>\n",
       "      <td>service_cpu_use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-27 22:49:56</td>\n",
       "      <td>10242.457500</td>\n",
       "      <td>service_cpu_use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-27 22:49:57</td>\n",
       "      <td>11901.568761</td>\n",
       "      <td>service_cpu_use</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date         value           metric\n",
       "0  2020-02-27 22:49:53   3504.829879  service_cpu_use\n",
       "1  2020-02-27 22:49:54   5742.951598  service_cpu_use\n",
       "2  2020-02-27 22:49:55   7981.073317  service_cpu_use\n",
       "3  2020-02-27 22:49:56  10242.457500  service_cpu_use\n",
       "4  2020-02-27 22:49:57  11901.568761  service_cpu_use"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if True:    \n",
    "    ltcy_sum_df = extractMetricSeries(timeseries_df,'metric','service_ltcy_sum')\n",
    "    ltcy_sum_df = toTimeSeries(ltcy_sum_df, value_col_name='service_ltcy_sum')\n",
    "    ltcy_sum_df.sort_index()\n",
    "\n",
    "    ltcy_count_df = extractMetricSeries(timeseries_df,'metric','service_ltcy_count' )  \n",
    "    ltcy_count_df = toTimeSeries(ltcy_count_df, value_col_name='service_ltcy_count')\n",
    "    ltcy_count_df.sort_index()\n",
    "\n",
    "    ltcy_df = ltcy_sum_df['service_ltcy_sum'] / ltcy_count_df['service_ltcy_count']\n",
    "\n",
    "    ltcy_df = pd.DataFrame(ltcy_df, columns=['value'])\n",
    "    ltcy_df['metric'] = 'service_ltcy_200'\n",
    "    ltcy_df.sort_index()\n",
    "\n",
    "    # check number of nulls\n",
    "    nulls = ltcy_df.isnull().sum()\n",
    "    if nulls['value'] > 0:\n",
    "        ltcy_df = ltcy_df.fillna(ltcy_df.mean())\n",
    "        \n",
    "    # add that to the time series and remove the ltcy count and sum signal\n",
    "\n",
    "    ltcy_df = ltcy_df.reset_index()\n",
    "\n",
    "    timeseries_df = pd.concat([timeseries_df, ltcy_df], ignore_index=True)\n",
    "\n",
    "    # remove service latency sum and count signals\n",
    "    timeseries_df = timeseries_df[timeseries_df.metric != 'service_ltcy_sum']\n",
    "    timeseries_df = timeseries_df[timeseries_df.metric != 'service_ltcy_count']\n",
    "\n",
    "timeseries_df.head(5)          \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>value</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-27 22:49:53</td>\n",
       "      <td>3504.829879</td>\n",
       "      <td>service_cpu_use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-27 22:49:54</td>\n",
       "      <td>5742.951598</td>\n",
       "      <td>service_cpu_use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-27 22:49:55</td>\n",
       "      <td>7981.073317</td>\n",
       "      <td>service_cpu_use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-27 22:49:56</td>\n",
       "      <td>10242.457500</td>\n",
       "      <td>service_cpu_use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-27 22:49:57</td>\n",
       "      <td>11901.568761</td>\n",
       "      <td>service_cpu_use</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date         value           metric\n",
       "0  2020-02-27 22:49:53   3504.829879  service_cpu_use\n",
       "1  2020-02-27 22:49:54   5742.951598  service_cpu_use\n",
       "2  2020-02-27 22:49:55   7981.073317  service_cpu_use\n",
       "3  2020-02-27 22:49:56  10242.457500  service_cpu_use\n",
       "4  2020-02-27 22:49:57  11901.568761  service_cpu_use"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add system_network_usage\n",
    "system_network_usage_df.sort_index()\n",
    "system_network_usage_df = system_network_usage_df.reset_index()\n",
    "timeseries_df = pd.concat([timeseries_df, system_network_usage_df], ignore_index=True)\n",
    "\n",
    "timeseries_df.head(5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving system_cpu_usage to file /Users/hmohamed/github/data-research-spring2020/raw-data-linode-run3/merged/all_data.csv with dimension (1073721, 3)\n"
     ]
    }
   ],
   "source": [
    "if save:\n",
    "    print('saving system_cpu_usage to file {} with dimension {}'.format(merged_dir + concated_data_file, timeseries_df.shape))       \n",
    "    timeseries_df.to_csv(path_or_buf=merged_dir + concated_data_file, index=True) \n",
    "else:\n",
    "    print(\"system_cpu_usage data is not saved. Savig flag is turned off!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>value</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-27 22:49:53</td>\n",
       "      <td>3504.829879</td>\n",
       "      <td>service_cpu_use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-27 22:49:54</td>\n",
       "      <td>5742.951598</td>\n",
       "      <td>service_cpu_use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-27 22:49:55</td>\n",
       "      <td>7981.073317</td>\n",
       "      <td>service_cpu_use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-27 22:49:56</td>\n",
       "      <td>10242.457500</td>\n",
       "      <td>service_cpu_use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-27 22:49:57</td>\n",
       "      <td>11901.568761</td>\n",
       "      <td>service_cpu_use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-02-27 22:49:58</td>\n",
       "      <td>10968.804868</td>\n",
       "      <td>service_cpu_use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-02-27 22:49:59</td>\n",
       "      <td>10126.117869</td>\n",
       "      <td>service_cpu_use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-02-27 22:50:00</td>\n",
       "      <td>11627.063366</td>\n",
       "      <td>service_cpu_use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-02-27 22:50:01</td>\n",
       "      <td>11425.092013</td>\n",
       "      <td>service_cpu_use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-02-27 22:50:02</td>\n",
       "      <td>10639.756226</td>\n",
       "      <td>service_cpu_use</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date         value           metric\n",
       "0  2020-02-27 22:49:53   3504.829879  service_cpu_use\n",
       "1  2020-02-27 22:49:54   5742.951598  service_cpu_use\n",
       "2  2020-02-27 22:49:55   7981.073317  service_cpu_use\n",
       "3  2020-02-27 22:49:56  10242.457500  service_cpu_use\n",
       "4  2020-02-27 22:49:57  11901.568761  service_cpu_use\n",
       "5  2020-02-27 22:49:58  10968.804868  service_cpu_use\n",
       "6  2020-02-27 22:49:59  10126.117869  service_cpu_use\n",
       "7  2020-02-27 22:50:00  11627.063366  service_cpu_use\n",
       "8  2020-02-27 22:50:01  11425.092013  service_cpu_use\n",
       "9  2020-02-27 22:50:02  10639.756226  service_cpu_use"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
