{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1- read processed file\n",
    "file_dir = '../../data/raw-data-linode-run3/'\n",
    "merged_dir = file_dir + 'merged/' \n",
    "\n",
    "# containers / istio input files\n",
    "service_cpu_usage_file = '1_service_cpu_use.csv'\n",
    "service_memory_usage_file = '2_service_memory_use.csv'\n",
    "service_cpu_sat_file = '3_service_cpu_sat.csv'\n",
    "service_net_usage_file = '4_service_net_usage.csv'\n",
    "service_disk_usage_file = '5_service_disk_usage.csv'\n",
    "service_req_total_file = '6_service_req_total.csv'\n",
    "service_ltcy_file = '7_service_ltcy.csv'\n",
    "service_errors_file = '8_service_errors.csv'\n",
    "service_request_size_file = '9_service_request_size.csv'\n",
    "service_response_size_file = '10_service_response_size.csv'\n",
    "containers_count_file = '11_containers_count.csv'\n",
    "\n",
    "# system input files\n",
    "system_cpu_usage_file = '12_system_cpu_usage.csv'\n",
    "\n",
    "\n",
    "service_input_files = [service_cpu_usage_file\n",
    "                      , service_memory_usage_file\n",
    "                      , service_cpu_sat_file\n",
    "                      , service_net_usage_file\n",
    "                      , service_disk_usage_file\n",
    "                      , service_req_total_file\n",
    "                      , service_ltcy_file\n",
    "                      , service_errors_file\n",
    "                      , service_request_size_file\n",
    "                      , service_response_size_file                       \n",
    "                      , containers_count_file\n",
    "                     ]\n",
    "\n",
    "system_input_files = [\n",
    "    system_cpu_usage_file\n",
    "]\n",
    "\n",
    "concated_data_file = 'all_data.csv'\n",
    "\n",
    "services = ['checkoutservice'\n",
    ",'cartservice'\n",
    ",'emailservice'\n",
    ",'currencyservice'\n",
    ",'paymentservice'\n",
    ",'productcatalogservice'\n",
    ",'shippingservice'\n",
    "] \n",
    "\n",
    "\n",
    "save=True\n",
    "frequency = '1S'  # S for second , T for minute\n",
    "\n",
    "rate_time_window = '1T'  # S for second , T for minute\n",
    "\n",
    "latency_percentile = 0.95\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T for minutes, S for seconds\n",
    "# remedy duplicates by either taking the maximum (=max) or average  (=mean) them\n",
    "def resample(df, value_column_name, index_col_name='date', frequency = frequency, interpolate = True\n",
    "             , interpolate_method = 'linear', base=6, dup = 'mean'):\n",
    "    # eliminate dups in timestamp\n",
    "    if dup == 'max':\n",
    "        df = df.groupby([index_col_name])[value_column_name].max()   # taking max\n",
    "        df = pd.DataFrame(df)\n",
    "    else:\n",
    "        df = df.groupby([index_col_name]).mean()   # taking mean\n",
    "        \n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df.sort_index(inplace=True)  # order the timeseries\n",
    "    \n",
    "    # fill in missing interval (upsample)\n",
    "    resampled = df.resample(frequency, kind='timestamp', base=base).bfill()\n",
    "    \n",
    "    if interpolate:\n",
    "        resampled = resampled.interpolate(method=interpolate_method)    \n",
    "        \n",
    "    return resampled\n",
    "\n",
    "def toTimeSeries(df, index_col_name='date', value_col_name='value'):\n",
    "    df[index_col_name] = pd.to_datetime(df[index_col_name])\n",
    "    df[value_col_name] = pd.to_numeric(df[value_col_name])\n",
    "    df.set_index(index_col_name, inplace=True)\n",
    "    df.sort_index(inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# This function extracts timeseries of one named service from the whole raw timeseries data\n",
    "def extractMetricSeries(df, col_name, col_value):\n",
    "    metric = df.loc[df[col_name] == col_value].drop([col_name], axis=1).rename(index=str, columns={\"value\": col_value})\n",
    "    metric.sort_index(inplace=True)\n",
    "    return metric\n",
    "\n",
    "# This function merges and alines the metrics timeseries data into a data frame, a column for every feature\n",
    "def expand(df, by_col, by_col_values, dup='mean'):\n",
    "    # first convert to time series\n",
    "    df = toTimeSeries(df, 'date')\n",
    "    metrics_df = pd.DataFrame()\n",
    "    i = 0\n",
    "    for col_value in by_col_values:\n",
    "        print(\"Processing metric for column: %\", col_value)\n",
    "        series = extractMetricSeries(df, by_col, col_value)\n",
    "        series = resample(series, value_column_name=col_value, dup=dup)\n",
    "        #service_series = diffSeries(service_series)   \n",
    "        if i == 0:\n",
    "            metrics_df = series\n",
    "        else:\n",
    "            metrics_df = merge(metrics_df, series)\n",
    "        i = i + 1\n",
    "    return metrics_df   \n",
    "\n",
    "# sum df rows, remove expanded columns and set a new column with a metric name\n",
    "def sumTimeseries(df, columns_to_delete, metric_name, metric_col_name='metric'):\n",
    "    df['value'] = df.sum(axis=1)\n",
    "    df[metric_col_name] = metric_name\n",
    "    for col in columns_to_delete:\n",
    "        df = df.drop([col], axis=1)\n",
    "    return df \n",
    "\n",
    "# max df rows, remove expanded columns and set a new column with a metric name\n",
    "def maxTimeseries(df, columns_to_delete, metric_name, metric_col_name='metric'):\n",
    "    df['value'] = df.max(axis=1)\n",
    "    df[metric_col_name] = metric_name\n",
    "    for col in columns_to_delete:\n",
    "        df = df.drop([col], axis=1)\n",
    "    return df\n",
    "\n",
    "# average df rows, remove expanded columns and set a new column with a metric name\n",
    "def avgTimeseries(df, columns_to_delete, metric_name, metric_col_name='metric'):\n",
    "    df['value'] = df.mean(axis=1)\n",
    "    df[metric_col_name] = metric_name\n",
    "    for col in columns_to_delete:\n",
    "        df = df.drop([col], axis=1)\n",
    "    return df\n",
    "\n",
    "# average df rows, remove expanded columns and set a new column with a metric name\n",
    "def countTimeseries(df, columns_to_delete, metric_name, metric_col_name='metric'):\n",
    "    df['value'] = df.count(axis=1)\n",
    "    df[metric_col_name] = metric_name\n",
    "    for col in columns_to_delete:\n",
    "        df = df.drop([col], axis=1)\n",
    "    return df\n",
    "\n",
    "def merge(df, series):\n",
    "    return pd.merge_asof(df, series, left_index=True, right_index=True, tolerance=pd.Timedelta('1 second')).bfill()    \n",
    "\n",
    "# df is a timeseries and resampled per second\n",
    "# window in a form of nS or nT  or nH , where n is an interger (S for seconds, T for minutes, H for hours)\n",
    "def rate(df, col, interval='S'):    \n",
    "    #df = df.resample('S', kind='timestamp', base=6).bfill()\n",
    "    df[col] = df.pct_change(fill_method='ffill', freq=interval)  # change per second\n",
    "    #df = df.resample(interval, kind='timestamp', base=6).mean()\n",
    "    df = df.dropna(axis=0, subset=[col])    \n",
    "    return df\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------- Start TESTING  --------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:01:00</th>\n",
       "      <td>-0.474699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:01:01</th>\n",
       "      <td>1.705744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:01:02</th>\n",
       "      <td>-0.949326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        value\n",
       "2020-01-01 00:01:00 -0.474699\n",
       "2020-01-01 00:01:01  1.705744\n",
       "2020-01-01 00:01:02 -0.949326"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = pd.date_range('1/1/2020', periods=72, freq='S')\n",
    "ts = pd.DataFrame(np.random.randn(len(rng)), index=rng, columns=['value'])\n",
    "ts = rate(ts, 'value', '1T')\n",
    "\n",
    "ts.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>ztime</th>\n",
       "      <th>service</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>service_cpu_usage</td>\n",
       "      <td>2020-02-28 05:59:52</td>\n",
       "      <td>productcatalogservice</td>\n",
       "      <td>0.036354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>service_cpu_usage</td>\n",
       "      <td>2020-02-28 05:59:33</td>\n",
       "      <td>productcatalogservice</td>\n",
       "      <td>0.036354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>service_cpu_usage</td>\n",
       "      <td>2020-02-28 05:59:15</td>\n",
       "      <td>productcatalogservice</td>\n",
       "      <td>0.036354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>service_cpu_usage</td>\n",
       "      <td>2020-02-28 05:59:04</td>\n",
       "      <td>productcatalogservice</td>\n",
       "      <td>0.036354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>service_cpu_usage</td>\n",
       "      <td>2020-02-28 05:58:40</td>\n",
       "      <td>productcatalogservice</td>\n",
       "      <td>0.036354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name                ztime                service     value\n",
       "0  service_cpu_usage  2020-02-28 05:59:52  productcatalogservice  0.036354\n",
       "1  service_cpu_usage  2020-02-28 05:59:33  productcatalogservice  0.036354\n",
       "2  service_cpu_usage  2020-02-28 05:59:15  productcatalogservice  0.036354\n",
       "3  service_cpu_usage  2020-02-28 05:59:04  productcatalogservice  0.036354\n",
       "4  service_cpu_usage  2020-02-28 05:58:40  productcatalogservice  0.036354"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service_test_df = pd.read_csv(file_dir + service_cpu_usage_file)\n",
    "service_test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>service</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-27 22:49:50</th>\n",
       "      <td>service_cpu_usage</td>\n",
       "      <td>productcatalogservice</td>\n",
       "      <td>0.036354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-27 22:49:52</th>\n",
       "      <td>service_cpu_usage</td>\n",
       "      <td>emailservice</td>\n",
       "      <td>0.034776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-27 22:49:53</th>\n",
       "      <td>service_cpu_usage</td>\n",
       "      <td>shippingservice</td>\n",
       "      <td>0.022885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-27 22:49:53</th>\n",
       "      <td>service_cpu_usage</td>\n",
       "      <td>checkoutservice</td>\n",
       "      <td>0.026960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-27 22:49:53</th>\n",
       "      <td>service_cpu_usage</td>\n",
       "      <td>currencyservice</td>\n",
       "      <td>0.032067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                metric                service     value\n",
       "date                                                                   \n",
       "2020-02-27 22:49:50  service_cpu_usage  productcatalogservice  0.036354\n",
       "2020-02-27 22:49:52  service_cpu_usage           emailservice  0.034776\n",
       "2020-02-27 22:49:53  service_cpu_usage        shippingservice  0.022885\n",
       "2020-02-27 22:49:53  service_cpu_usage        checkoutservice  0.026960\n",
       "2020-02-27 22:49:53  service_cpu_usage        currencyservice  0.032067"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service_test_df.rename(columns={'ztime': 'date', 'name':'metric'}, inplace=True)\n",
    "service_test_df = toTimeSeries(service_test_df, 'date')\n",
    "service_test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>cartservice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-27 22:49:53</th>\n",
       "      <td>service_cpu_usage</td>\n",
       "      <td>1763.896692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-27 22:49:57</th>\n",
       "      <td>service_cpu_usage</td>\n",
       "      <td>4005.321089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-27 22:49:59</th>\n",
       "      <td>service_cpu_usage</td>\n",
       "      <td>0.035686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-27 22:50:00</th>\n",
       "      <td>service_cpu_usage</td>\n",
       "      <td>2237.442300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-27 22:50:09</th>\n",
       "      <td>service_cpu_usage</td>\n",
       "      <td>1764.323045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 20:43:50</th>\n",
       "      <td>service_cpu_usage</td>\n",
       "      <td>2170.578358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 20:43:52</th>\n",
       "      <td>service_cpu_usage</td>\n",
       "      <td>1480.918093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 20:43:55</th>\n",
       "      <td>service_cpu_usage</td>\n",
       "      <td>0.024715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 20:43:56</th>\n",
       "      <td>service_cpu_usage</td>\n",
       "      <td>0.027122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 20:43:58</th>\n",
       "      <td>service_cpu_usage</td>\n",
       "      <td>965.891327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                metric  cartservice\n",
       "date                                               \n",
       "2020-02-27 22:49:53  service_cpu_usage  1763.896692\n",
       "2020-02-27 22:49:57  service_cpu_usage  4005.321089\n",
       "2020-02-27 22:49:59  service_cpu_usage     0.035686\n",
       "2020-02-27 22:50:00  service_cpu_usage  2237.442300\n",
       "2020-02-27 22:50:09  service_cpu_usage  1764.323045\n",
       "...                                ...          ...\n",
       "2020-02-28 20:43:50  service_cpu_usage  2170.578358\n",
       "2020-02-28 20:43:52  service_cpu_usage  1480.918093\n",
       "2020-02-28 20:43:55  service_cpu_usage     0.024715\n",
       "2020-02-28 20:43:56  service_cpu_usage     0.027122\n",
       "2020-02-28 20:43:58  service_cpu_usage   965.891327\n",
       "\n",
       "[51400 rows x 2 columns]"
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series = extractMetricSeries(service_test_df, 'service', 'cartservice')\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cartservice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-27 22:49:53</th>\n",
       "      <td>1763.896692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-27 22:49:57</th>\n",
       "      <td>4005.321089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-27 22:49:59</th>\n",
       "      <td>0.035686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-27 22:50:00</th>\n",
       "      <td>2237.442300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-27 22:50:09</th>\n",
       "      <td>1764.323045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 20:43:50</th>\n",
       "      <td>2170.578358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 20:43:52</th>\n",
       "      <td>1480.918093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 20:43:55</th>\n",
       "      <td>0.024715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 20:43:56</th>\n",
       "      <td>0.027122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-28 20:43:58</th>\n",
       "      <td>965.891327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33399 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     cartservice\n",
       "date                            \n",
       "2020-02-27 22:49:53  1763.896692\n",
       "2020-02-27 22:49:57  4005.321089\n",
       "2020-02-27 22:49:59     0.035686\n",
       "2020-02-27 22:50:00  2237.442300\n",
       "2020-02-27 22:50:09  1764.323045\n",
       "...                          ...\n",
       "2020-02-28 20:43:50  2170.578358\n",
       "2020-02-28 20:43:52  1480.918093\n",
       "2020-02-28 20:43:55     0.024715\n",
       "2020-02-28 20:43:56     0.027122\n",
       "2020-02-28 20:43:58   965.891327\n",
       "\n",
       "[33399 rows x 1 columns]"
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_df = series.groupby(['date'])['cartservice'].max()\n",
    "max_df = pd.DataFrame(max_df)\n",
    "\n",
    "max_df.index = pd.to_datetime(max_df.index)\n",
    "max_df.sort_index(inplace=True)\n",
    "#max_df['date'] = pd.to_datetime(max_df['date'])\n",
    "#max_df = toTimeSeries(max_df, value_col_name='cartservice')\n",
    "max_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------- END TESTING  --------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing input file 1_service_cpu_use.csv\n",
      "processing metric service_cpu_use\n",
      "Processing metric for column: % checkoutservice\n",
      "Processing metric for column: % cartservice\n",
      "Processing metric for column: % emailservice\n",
      "Processing metric for column: % currencyservice\n",
      "Processing metric for column: % paymentservice\n",
      "Processing metric for column: % productcatalogservice\n",
      "Processing metric for column: % shippingservice\n",
      "saving 1_service_cpu_use.csv data with shape (78845, 2)\n",
      "----------------\n",
      "processing input file 2_service_memory_use.csv\n",
      "processing metric service_memory_use\n",
      "Processing metric for column: % checkoutservice\n",
      "Processing metric for column: % cartservice\n",
      "Processing metric for column: % emailservice\n",
      "Processing metric for column: % currencyservice\n",
      "Processing metric for column: % paymentservice\n",
      "Processing metric for column: % productcatalogservice\n",
      "Processing metric for column: % shippingservice\n",
      "saving 2_service_memory_use.csv data with shape (78845, 2)\n",
      "----------------\n",
      "processing input file 3_service_cpu_sat.csv\n",
      "processing metric service_cpu_sat\n",
      "Processing metric for column: % checkoutservice\n",
      "Processing metric for column: % cartservice\n",
      "Processing metric for column: % emailservice\n",
      "Processing metric for column: % currencyservice\n",
      "Processing metric for column: % paymentservice\n",
      "Processing metric for column: % productcatalogservice\n",
      "Processing metric for column: % shippingservice\n",
      "saving 3_service_cpu_sat.csv data with shape (78845, 2)\n",
      "----------------\n",
      "processing input file 4_service_net_usage.csv\n",
      "processing metric service_net_usage\n",
      "Processing metric for column: % checkoutservice\n",
      "Processing metric for column: % cartservice\n",
      "Processing metric for column: % emailservice\n",
      "Processing metric for column: % currencyservice\n",
      "Processing metric for column: % paymentservice\n",
      "Processing metric for column: % productcatalogservice\n",
      "Processing metric for column: % shippingservice\n",
      "saving 4_service_net_usage.csv data with shape (78845, 2)\n",
      "----------------\n",
      "processing input file 5_service_disk_usage.csv\n",
      "processing metric service_disk_usage\n",
      "Processing metric for column: % checkoutservice\n",
      "Processing metric for column: % cartservice\n",
      "Processing metric for column: % emailservice\n",
      "Processing metric for column: % currencyservice\n",
      "Processing metric for column: % paymentservice\n",
      "Processing metric for column: % productcatalogservice\n",
      "Processing metric for column: % shippingservice\n",
      "saving 5_service_disk_usage.csv data with shape (78845, 2)\n",
      "----------------\n",
      "processing input file 6_service_req_total.csv\n",
      "processing metric service_req_total\n",
      "Processing metric for column: % checkoutservice\n",
      "Processing metric for column: % cartservice\n",
      "Processing metric for column: % emailservice\n",
      "Processing metric for column: % currencyservice\n",
      "Processing metric for column: % paymentservice\n",
      "Processing metric for column: % productcatalogservice\n",
      "Processing metric for column: % shippingservice\n",
      "saving 6_service_req_total.csv data with shape (78845, 2)\n",
      "----------------\n",
      "processing input file 7_service_ltcy.csv\n",
      "processing metric service_ltcy\n",
      "Processing metric for column: % checkoutservice\n",
      "Processing metric for column: % cartservice\n",
      "Processing metric for column: % emailservice\n",
      "Processing metric for column: % currencyservice\n",
      "Processing metric for column: % paymentservice\n",
      "Processing metric for column: % productcatalogservice\n",
      "Processing metric for column: % shippingservice\n",
      "saving 7_service_ltcy.csv data with shape (78845, 2)\n",
      "----------------\n",
      "processing input file 8_service_errors.csv\n",
      "processing metric service_errors\n",
      "Processing metric for column: % checkoutservice\n",
      "Processing metric for column: % cartservice\n",
      "Processing metric for column: % emailservice\n",
      "Processing metric for column: % currencyservice\n",
      "Processing metric for column: % paymentservice\n",
      "Processing metric for column: % productcatalogservice\n",
      "Processing metric for column: % shippingservice\n",
      "saving 8_service_errors.csv data with shape (78845, 2)\n",
      "----------------\n",
      "processing input file 9_service_request_size.csv\n",
      "processing metric service_request_size\n",
      "Processing metric for column: % checkoutservice\n",
      "Processing metric for column: % cartservice\n",
      "Processing metric for column: % emailservice\n",
      "Processing metric for column: % currencyservice\n",
      "Processing metric for column: % paymentservice\n",
      "Processing metric for column: % productcatalogservice\n",
      "Processing metric for column: % shippingservice\n",
      "saving 9_service_request_size.csv data with shape (78845, 2)\n",
      "----------------\n",
      "processing input file 10_service_response_size.csv\n",
      "processing metric service_response_size\n",
      "Processing metric for column: % checkoutservice\n",
      "Processing metric for column: % cartservice\n",
      "Processing metric for column: % emailservice\n",
      "Processing metric for column: % currencyservice\n",
      "Processing metric for column: % paymentservice\n",
      "Processing metric for column: % productcatalogservice\n",
      "Processing metric for column: % shippingservice\n",
      "saving 10_service_response_size.csv data with shape (78845, 2)\n",
      "----------------\n",
      "processing input file 11_containers_count.csv\n",
      "processing metric containers_count\n",
      "Processing metric for column: % checkoutservice\n",
      "Processing metric for column: % cartservice\n",
      "Processing metric for column: % emailservice\n",
      "Processing metric for column: % currencyservice\n",
      "Processing metric for column: % paymentservice\n",
      "Processing metric for column: % productcatalogservice\n",
      "Processing metric for column: % shippingservice\n",
      "saving 11_containers_count.csv data with shape (78845, 2)\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "# process istio and container metrics data signals\n",
    "for file in service_input_files:\n",
    "    orig_file = file\n",
    "    print('processing input file {}'.format(file))\n",
    "    pos = file.find('_')\n",
    "    metric_name = file[pos+1:]\n",
    "    pos = metric_name.find('.')\n",
    "    metric_name = metric_name[:pos]\n",
    "    print('processing metric {}'.format(metric_name))\n",
    "    \n",
    "    data_df = pd.read_csv(file_dir + file)\n",
    "    data_df.rename(columns={'ztime': 'date', 'name':'metric'}, inplace=True)\n",
    "    \n",
    "    if orig_file == containers_count_file:\n",
    "        remedy_dup = 'max'\n",
    "    else:\n",
    "        remedy_dup = 'mean'\n",
    "        \n",
    "    # expand and either average or max any duplicates in timestamps series\n",
    "    expanded_df = expand(data_df, by_col='service', by_col_values=services, dup=remedy_dup)\n",
    "    \n",
    "    # sum timeseries rows\n",
    "    sum_df = sumTimeseries(expanded_df, columns_to_delete=services, metric_name=metric_name)\n",
    "\n",
    "    if save:\n",
    "        print('saving {} data with shape {}'.format(orig_file, svc_cpu_usage_df_sum.shape))\n",
    "        save_to_file = merged_dir + orig_file\n",
    "        sum_df.to_csv(path_or_buf=save_to_file, index=True) \n",
    "        print(\"----------------\")\n",
    "    else:\n",
    "        print(\"Metric data is not saved. Savig flag is turned off!\")        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving 0.95 latency quantile file to ../../data/raw-data-linode-run3/merged/7_service_ltcy.csv with dimension (78781, 2)\n"
     ]
    }
   ],
   "source": [
    "# convert latency to percentile of rate change\n",
    "ltcy_file = merged_dir + service_ltcy_file\n",
    "ltcy_df = pd.read_csv(ltcy_file)\n",
    "ltcy_df = toTimeSeries(ltcy_df)\n",
    "\n",
    "metric = ltcy_df.metric[0]\n",
    "\n",
    "ltcy_df = ltcy_df.drop('metric', 1)\n",
    "ltcy_df = rate(ltcy_df, 'value', rate_time_window)\n",
    "ltcy_df = ltcy_df.groupby(['date']).quantile(latency_percentile)\n",
    "ltcy_df['metric'] = metric\n",
    "\n",
    "\n",
    "if save:\n",
    "    print('saving {} latency quantile file to {} with dimension {}'.format(Percentile, ltcy_file, ltcy_df.shape))       \n",
    "    ltcy_df.to_csv(path_or_buf=ltcy_file, index=True) \n",
    "else:\n",
    "    print(\"Latency percentils data is not saved. Savig flag is turned off!\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing metric for column: % 192.168.181.164\n",
      "Processing metric for column: % 192.168.228.12\n",
      "Processing metric for column: % 192.168.227.189\n",
      "Processing metric for column: % 192.168.189.71\n",
      "Processing metric for column: % 192.168.227.202\n",
      "saving system_cpu_usage to file ../../data/raw-data-linode-run3/merged/12_system_cpu_usage.csv with dimension (78841, 2)\n"
     ]
    }
   ],
   "source": [
    "# system_cpu_usage\n",
    "system_cpu_usage_df = pd.read_csv(file_dir + system_cpu_usage_file)\n",
    "system_cpu_usage_df.rename(columns={'ztime': 'date', 'name':'metric'}, inplace=True)\n",
    "\n",
    "# find nodes in the system\n",
    "nodes = system_cpu_usage_df.dropna(subset=['node']).node.unique()\n",
    "\n",
    "system_cpu_usage_expanded = expand(system_cpu_usage_df, by_col='node'\n",
    "                                   , by_col_values=nodes, dup='mean')\n",
    "\n",
    "system_cpu_usage_sum = sumTimeseries(system_cpu_usage_expanded, columns_to_delete=nodes\n",
    "                                          , metric_name='system_cpu_usage')\n",
    "\n",
    "if save:\n",
    "    print('saving system_cpu_usage to file {} with dimension {}'.format(merged_dir + system_cpu_usage_file, system_cpu_usage_sum.shape))       \n",
    "    system_cpu_usage_sum.to_csv(path_or_buf=merged_dir + system_cpu_usage_file, index=True) \n",
    "else:\n",
    "    print(\"system_cpu_usage data is not saved. Savig flag is turned off!\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate all data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data from ../../data/raw-data-linode-run3/merged/1_service_cpu_use.csv\n",
      "reading data from ../../data/raw-data-linode-run3/merged/2_service_memory_use.csv\n",
      "reading data from ../../data/raw-data-linode-run3/merged/3_service_cpu_sat.csv\n",
      "reading data from ../../data/raw-data-linode-run3/merged/4_service_net_usage.csv\n",
      "reading data from ../../data/raw-data-linode-run3/merged/5_service_disk_usage.csv\n",
      "reading data from ../../data/raw-data-linode-run3/merged/6_service_req_total.csv\n",
      "reading data from ../../data/raw-data-linode-run3/merged/7_service_ltcy.csv\n",
      "reading data from ../../data/raw-data-linode-run3/merged/8_service_errors.csv\n",
      "reading data from ../../data/raw-data-linode-run3/merged/9_service_request_size.csv\n",
      "reading data from ../../data/raw-data-linode-run3/merged/10_service_response_size.csv\n",
      "reading data from ../../data/raw-data-linode-run3/merged/11_containers_count.csv\n",
      "reading data from ../../data/raw-data-linode-run3/merged/12_system_cpu_usage.csv\n",
      "saving system_cpu_usage to file ../../data/raw-data-linode-run3/merged/all_data.csv with dimension (946047, 3)\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "all_files = service_input_files + system_input_files\n",
    "for file in all_files:\n",
    "    input_file = merged_dir + file\n",
    "    print('reading data from {}'.format(input_file))\n",
    "    input_df = pd.read_csv(input_file)\n",
    "    #input_df = toTimeSeries(input_df)\n",
    "    if i == 1:\n",
    "        timeseries_df = input_df\n",
    "    else:\n",
    "        timeseries_df = pd.concat([timeseries_df, input_df], ignore_index=True)\n",
    "    i = i +1\n",
    "\n",
    "if save:\n",
    "    print('saving system_cpu_usage to file {} with dimension {}'.format(merged_dir + concated_data_file, timeseries_df.shape))       \n",
    "    timeseries_df.to_csv(path_or_buf=merged_dir + concated_data_file, index=True) \n",
    "else:\n",
    "    print(\"system_cpu_usage data is not saved. Savig flag is turned off!\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
