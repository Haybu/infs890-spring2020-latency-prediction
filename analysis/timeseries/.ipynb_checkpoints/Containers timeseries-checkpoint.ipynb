{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1- read processed file\n",
    "file_dir = '../../data/raw-data-linode-run3/'\n",
    "merged_dir = file_dir + 'merged/' \n",
    "\n",
    "service_cpu_usage_file = '1_service_cpu_use.csv'\n",
    "service_memory_usage_file = '2_service_memory_use.csv'\n",
    "service_cpu_sat_file = '3_service_cpu_sat.csv'\n",
    "service_net_usage_file = '4_service_net_usage.csv'\n",
    "service_disk_usage_file = '5_service_disk_usage.csv'\n",
    "service_req_total_file = '6_service_req_total.csv'\n",
    "service_ltcy_file = '7_service_ltcy.csv'\n",
    "service_errors_file = '8_service_errors.csv'\n",
    "service_request_size_file = '9_service_request_size.csv'\n",
    "service_response_size_file = '10_service_response_size.csv'\n",
    "containers_count_file = '11_containers_count'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_files_to_sum = [service_cpu_usage_file\n",
    "                      , service_memory_usage_file\n",
    "                      , service_cpu_sat_file\n",
    "                      , service_net_usage_file\n",
    "                      , service_disk_usage_file\n",
    "                      , service_req_total_file\n",
    "                      , service_ltcy_file\n",
    "                      , service_errors_file\n",
    "                      , service_request_size_file\n",
    "                      , service_response_size_file \n",
    "                     ]\n",
    "\n",
    "# make sure to max for conainers count metric when fixing duplicates on timestamp entries\n",
    "input_files_to_max = [\n",
    "    containers_count_file\n",
    "]\n",
    "\n",
    "\n",
    "save=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(347791, 4)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_cpu_usage_df = pd.read_csv(file_dir + svc_cpu_usage_file)\n",
    "svc_cpu_usage_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>date</th>\n",
       "      <th>service</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>service_cpu_usage</td>\n",
       "      <td>2020-02-28 05:59:52</td>\n",
       "      <td>productcatalogservice</td>\n",
       "      <td>0.036354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>service_cpu_usage</td>\n",
       "      <td>2020-02-28 05:59:33</td>\n",
       "      <td>productcatalogservice</td>\n",
       "      <td>0.036354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>service_cpu_usage</td>\n",
       "      <td>2020-02-28 05:59:15</td>\n",
       "      <td>productcatalogservice</td>\n",
       "      <td>0.036354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>service_cpu_usage</td>\n",
       "      <td>2020-02-28 05:59:04</td>\n",
       "      <td>productcatalogservice</td>\n",
       "      <td>0.036354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>service_cpu_usage</td>\n",
       "      <td>2020-02-28 05:58:40</td>\n",
       "      <td>productcatalogservice</td>\n",
       "      <td>0.036354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              metric                 date                service     value\n",
       "0  service_cpu_usage  2020-02-28 05:59:52  productcatalogservice  0.036354\n",
       "1  service_cpu_usage  2020-02-28 05:59:33  productcatalogservice  0.036354\n",
       "2  service_cpu_usage  2020-02-28 05:59:15  productcatalogservice  0.036354\n",
       "3  service_cpu_usage  2020-02-28 05:59:04  productcatalogservice  0.036354\n",
       "4  service_cpu_usage  2020-02-28 05:58:40  productcatalogservice  0.036354"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_cpu_usage_df.rename(columns={'ztime': 'date', 'name':'metric'}, inplace=True)\n",
    "svc_cpu_usage_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    " services = ['checkoutservice'\n",
    ",'cartservice'\n",
    ",'emailservice'\n",
    ",'currencyservice'\n",
    ",'paymentservice'\n",
    ",'productcatalogservice'\n",
    ",'shippingservice'\n",
    "] \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toTimeSeries(df, index_col_name='date', value_col_name='value'):\n",
    "    df[index_col_name] = pd.to_datetime(df[index_col_name])\n",
    "    df[value_col_name] = pd.to_numeric(df[value_col_name])\n",
    "    df.set_index(index_col_name, inplace=True)\n",
    "    df.sort_index(inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# This function extracts timeseries of one named service from the whole raw timeseries data\n",
    "def extractMetricSeries(df, col_name, col_value):\n",
    "    metric = df.loc[df[col_name] == col_value].drop([col_name], axis=1).rename(index=str, columns={\"value\": col_value})\n",
    "    #metric.date = pd.to_datetime(metric.date)\n",
    "    #metric[name] = pd.to_numeric(metric[name])\n",
    "    #metric.set_index('date', inplace=True)\n",
    "    metric.sort_index(inplace=True)\n",
    "    return metric\n",
    "\n",
    "# T for minutes, S for seconds\n",
    "# aggregate of duplicates could be either by taking the maximum (=max) or average  (=rate)\n",
    "def resample(df, index_col_name='date', frequency = 'S', interpolate = True\n",
    "             , interpolate_method = 'linear', base=6, aggregate = 'rate'):\n",
    "    # eliminate dups in timestamp\n",
    "    if aggregate == 'max':\n",
    "        df = df.groupby([index_col_name]).max()   # taking max\n",
    "    else:\n",
    "        df = df.groupby([index_col_name]).mean()   # taking mean\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    # fill in missing interval (upsample)\n",
    "    resampled = df.resample(frequency, kind='timestamp', base=base).bfill()\n",
    "    if interpolate:\n",
    "        resampled = resampled.interpolate(method=interpolate_method)\n",
    "    return resampled\n",
    "\n",
    "# This function merges and alines the metrics timeseries data into a data frame, a column for every feature\n",
    "def expand(df, by_col, by_col_values):\n",
    "    # first convert to time series\n",
    "    df = toTimeSeries(df, 'date')\n",
    "    metrics_df = pd.DataFrame()\n",
    "    i = 0\n",
    "    for col_value in by_col_values:\n",
    "        print(\"Processing metric for column: %\", col_value)\n",
    "        series = extractMetricSeries(df, by_col, col_value)\n",
    "        series = resample(series)\n",
    "        #service_series = diffSeries(service_series)   \n",
    "        if i == 0:\n",
    "            metrics_df = series\n",
    "        else:\n",
    "            metrics_df = merge(metrics_df, series)\n",
    "        i = i + 1\n",
    "    return metrics_df   \n",
    "\n",
    "def sumMetrics(df, columns_to_delete, metric_name, metric_col_name='metric'):\n",
    "    df['value'] = df.sum(axis=1)\n",
    "    df[metric_col_name] = metric_name\n",
    "    for col in columns_to_delete:\n",
    "        df = df.drop([col], axis=1)\n",
    "    return df    \n",
    "\n",
    "def merge(df, series):\n",
    "    return pd.merge_asof(df, series, left_index=True, right_index=True, tolerance=pd.Timedelta('1 second')).bfill()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svc_cpu_usage_df_expanded = expand(svc_cpu_usage_df, 'service', services)\n",
    "#svc_cpu_usage_df_sum = sumMetrics(svc_cpu_usage_df_expanded, services, 'svc_cpu_usage')\n",
    "\n",
    "#if False:\n",
    "#    print(\"saving 1_svc_cpu_usage of shape {}\".format(svc_cpu_usage_df_sum.shape))\n",
    "#    save_to_file = merged_dir + '1_svc_cpu_usage'\n",
    "#    svc_cpu_usage_df_sum.to_csv(path_or_buf=save_to_file, index=True)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing input file 1_service_cpu_use.csv\n",
      "processing metric service_cpu_use\n",
      "Processing metric for column: % checkoutservice\n",
      "Processing metric for column: % cartservice\n",
      "Processing metric for column: % emailservice\n",
      "Processing metric for column: % currencyservice\n",
      "Processing metric for column: % paymentservice\n",
      "Processing metric for column: % productcatalogservice\n",
      "Processing metric for column: % shippingservice\n",
      "saving 1_service_cpu_use.csv of shape (78845, 2)\n",
      "----------------\n",
      "processing input file 2_service_memory_use.csv\n",
      "processing metric service_memory_use\n",
      "Processing metric for column: % checkoutservice\n",
      "Processing metric for column: % cartservice\n",
      "Processing metric for column: % emailservice\n",
      "Processing metric for column: % currencyservice\n",
      "Processing metric for column: % paymentservice\n",
      "Processing metric for column: % productcatalogservice\n",
      "Processing metric for column: % shippingservice\n",
      "saving 2_service_memory_use.csv of shape (78845, 2)\n",
      "----------------\n",
      "processing input file 3_service_cpu_sat.csv\n",
      "processing metric service_cpu_sat\n",
      "Processing metric for column: % checkoutservice\n",
      "Processing metric for column: % cartservice\n",
      "Processing metric for column: % emailservice\n",
      "Processing metric for column: % currencyservice\n",
      "Processing metric for column: % paymentservice\n",
      "Processing metric for column: % productcatalogservice\n",
      "Processing metric for column: % shippingservice\n",
      "saving 3_service_cpu_sat.csv of shape (78845, 2)\n",
      "----------------\n",
      "processing input file 4_service_net_usage.csv\n",
      "processing metric service_net_usage\n",
      "Processing metric for column: % checkoutservice\n",
      "Processing metric for column: % cartservice\n",
      "Processing metric for column: % emailservice\n",
      "Processing metric for column: % currencyservice\n",
      "Processing metric for column: % paymentservice\n",
      "Processing metric for column: % productcatalogservice\n",
      "Processing metric for column: % shippingservice\n",
      "saving 4_service_net_usage.csv of shape (78845, 2)\n",
      "----------------\n",
      "processing input file 5_service_disk_usage.csv\n",
      "processing metric service_disk_usage\n",
      "Processing metric for column: % checkoutservice\n",
      "Processing metric for column: % cartservice\n",
      "Processing metric for column: % emailservice\n",
      "Processing metric for column: % currencyservice\n",
      "Processing metric for column: % paymentservice\n",
      "Processing metric for column: % productcatalogservice\n",
      "Processing metric for column: % shippingservice\n",
      "saving 5_service_disk_usage.csv of shape (78845, 2)\n",
      "----------------\n",
      "processing input file 6_service_req_total.csv\n",
      "processing metric service_req_total\n",
      "Processing metric for column: % checkoutservice\n",
      "Processing metric for column: % cartservice\n",
      "Processing metric for column: % emailservice\n",
      "Processing metric for column: % currencyservice\n",
      "Processing metric for column: % paymentservice\n",
      "Processing metric for column: % productcatalogservice\n",
      "Processing metric for column: % shippingservice\n",
      "saving 6_service_req_total.csv of shape (78845, 2)\n",
      "----------------\n",
      "processing input file 7_service_ltcy.csv\n",
      "processing metric service_ltcy\n",
      "Processing metric for column: % checkoutservice\n",
      "Processing metric for column: % cartservice\n",
      "Processing metric for column: % emailservice\n",
      "Processing metric for column: % currencyservice\n",
      "Processing metric for column: % paymentservice\n",
      "Processing metric for column: % productcatalogservice\n",
      "Processing metric for column: % shippingservice\n",
      "saving 7_service_ltcy.csv of shape (78845, 2)\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "for file in input_files_to_sum:\n",
    "    orig_file = file\n",
    "    print('processing input file {}'.format(file))\n",
    "    pos = file.find('_')\n",
    "    metric_name = file[pos+1:]\n",
    "    pos = metric_name.find('.')\n",
    "    metric_name = metric_name[:pos]\n",
    "    print('processing metric {}'.format(metric_name))\n",
    "    \n",
    "    data_df = pd.read_csv(file_dir + file)\n",
    "    data_df.rename(columns={'ztime': 'date', 'name':'metric'}, inplace=True)\n",
    "    expanded_df = expand(data_df, 'service', services)\n",
    "    sum_df = sumMetrics(expanded_df, services, metric_name)\n",
    "\n",
    "    if save:\n",
    "        print('saving {} data with shape {}'.format(orig_file, svc_cpu_usage_df_sum.shape))\n",
    "        save_to_file = merged_dir + orig_file\n",
    "        sum_df.to_csv(path_or_buf=save_to_file, index=True) \n",
    "        print(\"----------------\")\n",
    "    else:\n",
    "        print(\"Metric data is not saved. Savig flag is turned off!\")        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving 0.95 latency quantile file to ../../data/raw-data-linode-run3/merged/7_service_ltcy.csv with dimension (78841, 2)\n"
     ]
    }
   ],
   "source": [
    "# convert latency to percentile (chooing 95)\n",
    "Percentile = 0.95\n",
    "\n",
    "ltcy_file = merged_dir + service_ltcy_file\n",
    "ltcy_df = pd.read_csv(ltcy_file)\n",
    "ltcy_df = toTimeSeries(ltcy_df)\n",
    "metric_series = ltcy_df.metric\n",
    "ltcy_df = ltcy_df.drop('metric', 1)\n",
    "ltcy_df = ltcy_df.groupby(['date']).quantile(Percentile)\n",
    "ltcy_df['metric'] = metric_series\n",
    "\n",
    "if save:\n",
    "    print('saving {} latency quantile file to {} with dimension {}'.format(Percentile, ltcy_file, ltcy_df.shape))       \n",
    "    ltcy_df.to_csv(path_or_buf=ltcy_file, index=True) \n",
    "else:\n",
    "    print(\"Latency percentils data is not saved. Savig flag is turned off!\")   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
